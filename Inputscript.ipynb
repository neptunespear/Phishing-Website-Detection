{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tldextract import extract\n",
    "import ssl\n",
    "import socket\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import whois\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to get response from text\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "except:\n",
    "    response = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check wether URL has IP\n",
    "def url_having_ip(url):\n",
    "#using regular function\n",
    "    symbol = re.findall(r'(http((s)?)://)((((\\d)+).)*)((\\w)+)(/((\\w)+))?',url)\n",
    "    if(len(symbol)!=0):\n",
    "        having_ip = 1 #phishing\n",
    "        return 1\n",
    "    else:\n",
    "        having_ip = -1 #legitimate\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the length of URL\n",
    "def url_length(url):\n",
    "    length=len(url)\n",
    "    if(length<54):\n",
    "        return -1\n",
    "    elif(54<=length<=75):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if URL is short\n",
    "def url_short(url):\n",
    "    if re.findall(\"goo.gl|bit.ly\", url):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for @ Symbol\n",
    "def having_at_symbol(url):\n",
    "    symbol=re.findall(r'@',url)\n",
    "    if(len(symbol)==0):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for //\n",
    "def doubleSlash(url):\n",
    "    if(url.count('//') > 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Prefix and Suffix\n",
    "def prefix_suffix(url):\n",
    "    subDomain, domain, suffix = extract(url)\n",
    "    if(domain.count('-')):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Sub domains\n",
    "def sub_domain(url):\n",
    "    subDomain, domain, suffix = extract(url)\n",
    "    if(subDomain.count('.')==0):\n",
    "        return -1\n",
    "    elif(subDomain.count('.')==1):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find SSL final state\n",
    "def SSLfinal_State(url):\n",
    "    try:\n",
    "#check wheather contains https       \n",
    "        if(re.search('^https',url)):\n",
    "            usehttps = 1\n",
    "        else:\n",
    "            usehttps = 0\n",
    "#getting the certificate issuer to later compare with trusted issuer \n",
    "#getting host name\n",
    "        subDomain, domain, suffix = extract(url)\n",
    "        host_name = domain + \".\" + suffix\n",
    "        context = ssl.create_default_context()\n",
    "        sct = context.wrap_socket(socket.socket(), server_hostname = host_name)\n",
    "        sct.connect((host_name, 443))\n",
    "        certificate = sct.getpeercert()\n",
    "        issuer = dict(x[0] for x in certificate['issuer'])\n",
    "        certificate_Auth = str(issuer['commonName'])\n",
    "        certificate_Auth = certificate_Auth.split()\n",
    "        if(certificate_Auth[0] == \"Network\" or certificate_Auth == \"Deutsche\"):\n",
    "            certificate_Auth = certificate_Auth[0] + \" \" + certificate_Auth[1]\n",
    "        else:\n",
    "            certificate_Auth = certificate_Auth[0] \n",
    "        trusted_Auth = ['Comodo','Symantec','GoDaddy','GlobalSign','DigiCert','StartCom','Entrust','Verizon','Trustwave','Unizeto','Buypass','QuoVadis','Deutsche Telekom','Network Solutions','SwissSign','IdenTrust','Secom','TWCA','GeoTrust','Thawte','Doster','VeriSign']        \n",
    "#getting age of certificate\n",
    "        startingDate = str(certificate['notBefore'])\n",
    "        endingDate = str(certificate['notAfter'])\n",
    "        startingYear = int(startingDate.split()[3])\n",
    "        endingYear = int(endingDate.split()[3])\n",
    "        Age_of_certificate = endingYear-startingYear\n",
    "        \n",
    "#checking final conditions\n",
    "        if((usehttps==1) and (certificate_Auth in trusted_Auth) and (Age_of_certificate>=1) ):\n",
    "            return -1 #legitimate\n",
    "        elif((usehttps==1) and (certificate_Auth not in trusted_Auth)):\n",
    "            return 0 #suspicious\n",
    "        else:\n",
    "            return 1 #phishing\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if domain is registered\n",
    "def domain_registration(url):\n",
    "    try:\n",
    "        w = whois.whois(url)\n",
    "        updated = w.updated_date\n",
    "        exp = w.expiration_date\n",
    "        length = (exp[0]-updated[0]).days\n",
    "        if(length<=365):\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Fevicon\n",
    "def favicon(url):\n",
    "    return 0#Cannot be determined only with URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Port\n",
    "def port(url):\n",
    "    return 0#Cannot be determined only with URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if http token exists\n",
    "def https_token(url):\n",
    "    subDomain, domain, suffix = extract(url)\n",
    "    host =subDomain +'.' + domain + '.' + suffix \n",
    "    if(host.count('https')):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Request for URL\n",
    "def request_url(url):\n",
    "    try:\n",
    "        subDomain, domain, suffix = extract(url)\n",
    "        websiteDomain = domain\n",
    "        \n",
    "        opener = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(opener, 'lxml')\n",
    "        imgs = soup.findAll('img', src=True)\n",
    "        total = len(imgs)\n",
    "        \n",
    "        linked_to_same = 0\n",
    "        avg =0\n",
    "        for image in imgs:\n",
    "            subDomain, domain, suffix = extract(image['src'])\n",
    "            imageDomain = domain\n",
    "            if(websiteDomain==imageDomain or imageDomain==''):\n",
    "                linked_to_same = linked_to_same + 1\n",
    "        vids = soup.findAll('video', src=True)\n",
    "        total = total + len(vids)\n",
    "        \n",
    "        for video in vids:\n",
    "            subDomain, domain, suffix = extract(video['src'])\n",
    "            vidDomain = domain\n",
    "            if(websiteDomain==vidDomain or vidDomain==''):\n",
    "                linked_to_same = linked_to_same + 1\n",
    "        linked_outside = total-linked_to_same\n",
    "        if(total!=0):\n",
    "            avg = linked_outside/total\n",
    "            \n",
    "        if(avg<0.22):\n",
    "            return -1\n",
    "        elif(0.22<=avg<=0.61):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for anchor element\n",
    "def url_of_anchor(url):\n",
    "    try:\n",
    "        subDomain, domain, suffix = extract(url)\n",
    "        websiteDomain = domain\n",
    "        \n",
    "        opener = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(opener, 'lxml')\n",
    "        anchors = soup.findAll('a', href=True)\n",
    "        total = len(anchors)\n",
    "        linked_to_same = 0\n",
    "        avg = 0\n",
    "        for anchor in anchors:\n",
    "            subDomain, domain, suffix = extract(anchor['href'])\n",
    "            anchorDomain = domain\n",
    "            if(websiteDomain==anchorDomain or anchorDomain==''):\n",
    "                linked_to_same = linked_to_same + 1\n",
    "        linked_outside = total-linked_to_same\n",
    "        if(total!=0):\n",
    "            avg = linked_outside/total\n",
    "            \n",
    "        if(avg<0.31):\n",
    "            return -1\n",
    "        elif(0.31<=avg<=0.67):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for links in tags\n",
    "def Links_in_tags(url):\n",
    "    try:\n",
    "        opener = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(opener, 'lxml')\n",
    "        \n",
    "        no_of_meta =0\n",
    "        no_of_link =0\n",
    "        no_of_script =0\n",
    "        anchors=0\n",
    "        avg =0\n",
    "        for meta in soup.find_all('meta'):\n",
    "            no_of_meta = no_of_meta+1\n",
    "        for link in soup.find_all('link'):\n",
    "            no_of_link = no_of_link +1\n",
    "        for script in soup.find_all('script'):\n",
    "            no_of_script = no_of_script+1\n",
    "        for anchor in soup.find_all('a'):\n",
    "            anchors = anchors+1\n",
    "        total = no_of_meta + no_of_link + no_of_script+anchors\n",
    "        tags = no_of_meta + no_of_link + no_of_script\n",
    "        if(total!=0):\n",
    "            avg = tags/total\n",
    "\n",
    "        if(avg<0.25):\n",
    "            return -1\n",
    "        elif(0.25<=avg<=0.81):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1        \n",
    "    except:        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfh(url):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_submit(url):\n",
    "    try:\n",
    "        opener = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(opener, 'lxml')\n",
    "        if(soup.find('mailto:')):\n",
    "            return 1\n",
    "        else:\n",
    "            return -1 \n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abnormal_url(url):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redirect(url):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_mouseover(url):\n",
    "    if re.findall(\"<script>.+onmouseover.+</script>\", response):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rightClick(url):\n",
    "    if re.findall(r\"event.button ?== ?2\", response):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popup(url):\n",
    "    if re.findall(r\"alert\\(\", response):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iframe(url):\n",
    "    if re.findall(r\"[<iframe>|<frameBorder>]\", response):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_of_domain(url):\n",
    "    try:\n",
    "        w = whois.query(url)\n",
    "        start_date = w.creation_date\n",
    "        current_date = datetime.datetime.now()\n",
    "        age =(current_date-start_date[0]).days\n",
    "        if(age>=180):\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    except Exception as e:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not possible to find DNS of URL\n",
    "def dns(url):\n",
    "    #ongoing\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not possible to find web traffic\n",
    "def web_traffic(url):\n",
    "    #ongoing\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not possible to find page rank as Google has blocked API's\n",
    "def page_rank(url):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not possible to google index find as Google has blocked API's\n",
    "def google_index(url):\n",
    "    #ongoing\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not possible to find with URL only\n",
    "def links_pointing(url):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not possible to find with URL only\n",
    "def statistical(url):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(url):    \n",
    "    check = [[url_having_ip(url),url_length(url),url_short(url),having_at_symbol(url),\n",
    "             doubleSlash(url),prefix_suffix(url),sub_domain(url),SSLfinal_State(url),\n",
    "              domain_registration(url),favicon(url),port(url),https_token(url),request_url(url),\n",
    "              url_of_anchor(url),Links_in_tags(url),sfh(url),email_submit(url),abnormal_url(url),\n",
    "              redirect(url),on_mouseover(url),rightClick(url),popup(url),iframe(url),\n",
    "              age_of_domain(url),dns(url),web_traffic(url),page_rank(url),google_index(url),\n",
    "              links_pointing(url),statistical(url)]]\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
